TARGET DECK: D204


What might be developed by data analysts when acquiring data from a data warehouse? #flashcard 
The SQL queries of data within the tables
<!--ID: 1617742955574-->





Which mistake is commonly made during the predictive analytics phase? #flashcard 
The model is developed before the research question is known.
<!--ID: 1617742955596-->




What strategy will contribute to effective data representation and      reporting #flashcard 
Excluding unrelated data


 
 what happens during the discovery phase #flashcard 
	1. Meet with stakeholders
	2. Identify business needs
	3. Define the question
	4. Do we have the data we need to answer the question?
	5. Organize resources
	6. Coordinate people
	
	
<!--ID: 1615581511175-->


	
What happens during the reporting phase? #flashcard 
	1. Create a story to report data in a meaningful, in-context way
	2. Remove irrelevant variables
	3. Use visuals to communicate the story
	4. Present it to stakeholders
	5. Revisit the model to make improvements and adjustments as needed
	6. Archive assets
<!--ID: 1617742976574-->






What happens during the data acquisition phase?  #flashcard 
	1. Get the data from various sources
	2. Data cleaning (most time consuming part of process)
	3. Detecting missing values - defining data columns that could contain null values, etc.
<!--ID: 1617742978091-->




 What happens during the Data Mining phase? #flashcard 
	 1. Finding patterns and insights
	2. Test hypotheses
	3. Refine
<!--ID: 1617742989049-->




	
What is involved in the wrangling phase? #flashcard 
	5. Get data
	6. Clean data
	7. Explore data
	8. Refine data
<!--ID: 1617743012544-->






Infographics #flashcard 
- “a visual representation of information or data”.
- But the meaning of an infographic is something much more specific.
-  An infographic is a collection of imagery, charts, and minimal text that gives an easy-to-understand overview of a topic.
<!--ID: 1617743014570-->




Name the steps of Data analytics Life cycle #flashcard 
![[Pasted image 20210323153648.png]]
<!--ID: 1617743026043-->



1st Step Business Understanding #flashcard 
This phase is also known as the discovery phase. During this phase, an analyst defines the major questions of interest that need to be answered,
understand the needs of the stakeholders, and assess the resource constraints of the project
<!--ID: 1617743026064-->



2nd step Data acquisition #flashcard 
– This is the phase of collecting data. Frequently, data will be retrieved
from a database, perhaps a component of a data warehouse, by using a language like SQL. Sometimes data might not be available and the analyst will use tools such as web scraping or surveys to acquire it.
<!--ID: 1617743046419-->




3rd step Data cleaning #flashcard 
This phase is referred to by a variety of names. Common alternative
terms include data cleansing, data wrangling, data munging, and feature engineering. When this phase is ignored or skipped, the results from the analysis may become irrelevant. There is no one common tool supporting this phase. An analyst will use SQL, Python, R, or Excel to perform various data modifications and transformations.
<!--ID: 1617743046442-->




4th step Data exploration #flashcard 
In this phase, the analyst begins to understand the basic nature of
data and the relationships within it. This phase often relies on the use of data visualization tools and numerical summaries, such as measures of central tendency and variability.
<!--ID: 1617743046455-->





5th Step Predictive Modeling #flashcard 
These tools enable an analyst to move beyond describing the data
to creating models that enable predicting outcomes of interest. Tools such as Python and R play an important role in automating the training and using of models.
<!--ID: 1617743046467-->




6th step Data mining  and Machine learning #flashcard 
These tools became popular with the ability of computers to look for
patterns in large amounts of data. In the industry, you will sometimes find terms like machine learning used in place of data mining
**look for patterns and test hypothesis**
<!--ID: 1617743058243-->




7th step Reporting and Visualization #flashcard 
In this phase, an analyst tells the story of the data and
uses graphs or interactive dashboards to inform others of the findings from the analyses. Interactive dashboards tools, such as Tableau, allow even the novice user the ability to interact with the data and spot trends and patterns
<!--ID: 1617743058260-->





Data science Pathway #flashcard 
1. planning
	1. define the goals
	2. organize resources
	3. coordinate people 
	4. schedule project
2. Wrangling 
	1. get data 
	2. clean data
	3. explore data
	4. refine data
3. modeling 
	1. create model
	2. validate model
	3. evaluate model
	4. refine model
4. applying 
	1. present model
	2. deploy model
	3. revisit model
	4. achieve assets 
<!--ID: 1617743065721-->




Name the project roles and explain what they do #flashcard 
- Project sponsor – champions the vision of the project; has the authority to allocate resources
- Project manager – makes sure things get done on time and within budget; removes roadblocks
	 - Avoid scope creep (new requirements are added to the project that increases the time/resources needed to complete it)
- Engineer – devs, architects; focus on hardware and software that enable data science
- Machine Learning Specialist – pro in CS and math; deep learning, artificial intelligence
- Researcher – subject matter expert, high statistical expertise
- Analyst – web analytics, SQL, visualizations
- The “Unicorn” – someone who does all of the above
	 - Very rare and very expensive; dangerous to rely on one person 
	  - The goal is to create a “unicorn” by having the right team
<!--ID: 1617743077220-->




Central Limit theorem #flashcard 
 if you have enough sample groups, the mean of those sample groups will tend to follow a normal distribution (bell curve)
<!--ID: 1617743077240-->




Regression #flashcard 
- model the relationship between two variables; predict binary outcomes
	- Be sure to choose variables which can be controlled
<!--ID: 1617743092166-->



Nearest Neighbors #flashcard 
- model the relationship between two variables; predict binary outcomes
	- Be sure to choose variables which can be controlled
<!--ID: 1617743092188-->




Time series analysis #flashcard 
looking at a variable over time
<!--ID: 1617743092197-->




Optimization #flashcard 
- what value a variable should have, given certain conditions or restraints
	- Example: the price of lemonade when you have x lemons, y amount of sugar, z cups at a certain price
<!--ID: 1617743104445-->




Bayes Theorem #flashcard 
- the probability of an event, based on some relevant knowledge
	- Example: You test positive for a certain medical condition. Given the false positive rate, how likely is it that it’s a true positive vs. a false positive?
<!--ID: 1616530120477-->



Business Understanding #flashcard 
**Aka Planning discovery** 
# topics of interest 
 - scope projects 
 - identify stakeholders and research questions/KPI
 - identify timeline, budget, and participants 
# potential problems 
Lack of clear focus on stakeholders, timeline, limitations and budget could potentially derail an analysis
<!--ID: 1617743104454-->




Data acquisition v2 #flashcard 
![[Pasted image 20210402114524.png]]
<!--ID: 1617743104465-->




Data cleaning v2223 #flashcard 
![[Pasted image 20210402114617.png]]
<!--ID: 1617743104474-->




Data exploration V4 #flashcard 
![[Pasted image 20210402115205.png]]
<div style="width:100%;height:0;padding-bottom:73%;position:relative;"><iframe src="https://giphy.com/embed/12JrA4UscbcwUw" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen></iframe></div><p><a href="https://giphy.com/gifs/statistics-excel-probability-12JrA4UscbcwUw"></a></p>
<!--ID: 1617743112817-->





predictive Modeling V4 #flashcard 
![[Pasted image 20210402115341.png]]
<!--ID: 1617378837358-->

Data mining V4 #flashcard 
![[Pasted image 20210402115451.png]]
<!--ID: 1617743125170-->



Reporting and visualization #flashcard 
![[Pasted image 20210403200654.png]]
<!--ID: 1617743133066-->




Descriptive, Diagnostic, Predictive, Prescriptive #flashcard 
![[Pasted image 20210402115743.png]]
<!--ID: 1617743133087-->




Correlation Vs causation #flashcard 
- ==A conclusion of causality based on a correlation is a common mistake in both **predictive and data mining models.**==
- Correlation is a relationship between two variables: when one variable changes, you know the degree in which the other variable change   
- Causation is when there is a real-world explanation for why this is logically happening; it implies a cause and effect.
<!--ID: 1617743140943-->



Business Vs academic research questions #flashcard 
![[Pasted image 20210402122033.png]]
<!--ID: 1617743140963-->



Internal vs external data #flashcard 
![[Pasted image 20210402122435.png]]
<!--ID: 1617743140976-->




  
  More on soft skills #flashcard 
- Persuasion is an essential soft skill needed by a data analyst.  Persuasion involves several other common soft skills, including:
	- Communication
	- Emotional intelligence- the capacity to be aware of, control, and express one's emotions, and to handle interpersonal relationships judiciously and empathetically.
	- Active listening- Active listening refers to a pattern of listening that keeps you engaged with your conversation partner in a positive way. It is the process of listening attentively while someone else speaks, paraphrasing and reflecting back what is said, and withholding judgment and advice.
	- Logic and reasoning
	- interpersonal skills
	- Negotiation
<!--ID: 1617743161139-->



Regression, classification and clustering #flashcard 
![[Pasted image 20210402124129.png]]
# Regression - 
 -  is a technique that allows us to predict an outcome (either numerical or categorical) based on a set of predictor variables.  One might think of this process as providing an output given a set of input variables.  For example, an analyst might predict the churn of customers based upon various customer demographic data.
 ____
# classification 
-  is a technique in which the analyst wants to assign an item to a specific category based on various conditions.  The general approach that the model uses is to find the location of the item needing classification among measurements of interest (locate), compare this item to items in close proximity among the variables of interest (compare), and then assign the item to the group it most resembles (assign).  For example, if a person found an anonymous paper thought to be written by Shakespeare, they might look at various data for writings: reading level, word count, average word length, etc.  One would then find this anonymous paper compared to other Shakespeare writings (locate), see how similar it is to other writings of Shakespeare vs non-Shakespeare writings (compare), and then make a decision if the paper appears to be written by Shakespeare (assign)
____
# clustering 
- Whereas classification attempts to identify an unknown object among known groups, clustering is the opposite: the groupings are unknown and the analyst wishes to determine if the objects belong to any groups, and if so, how many groups exist.  For example, an analyst might take search queries on the Apple company to determine if they group in any particular ways.  After analyzing the data and applying classification techniques, they believe that people search on either Apple history, or current Apple news.
<!--ID: 1617743170416-->



Structure , semi-structured and unstructured #flashcard 
![[Pasted image 20210402124653.png]]
<!--ID: 1617743182041-->




XML VS JSON #flashcard 
![[Pasted image 20210402124901.png]]
![[Pasted image 20210402124930.png]]
# xml is tree structured and json is map structured  
<!--ID: 1617743182057-->





Univariate Analysis #flashcard 
- Univariate analysis is the simplest of the three analyses where the data you are analyzing is only one variable. There are many different ways people use univariate analysis. The most common univariate analysis is checking the ==central tendency (mean, median and mode), the range, the maximum and minimum values, and standard deviation of a variable.==
- Common visual technique used for univariate analysis is a histogram, which is a frequency distribution graph. You could also use a box plot or violin plot to compare the spread of the variables and provides an insight into outliers. Using any of the above mentioned to compare the “sepal_length” in the iris dataset across species is only comparing one variable, therefore a Univariate analysis.
<!--ID: 1617743187818-->



Bivariate Analysis #flashcard 
- Bivariate analysis is where you are comparing two variables to study their relationships. These variables could be dependent or independent to each other. In Bivariate analysis is that there is always a Y-value for each X-value.
- The most common visual technique for bivariate analysis is a **scatter plot, where one variable is on the x-axis and the other on the y-axis.** In addition to the scatter plot, regression plot and correlation coefficient are also frequently used to study the relationship of the variables. For example, continuing with the iris dataset, you can compare “sepal_length” vs “sepal_width” or “sepal_length” vs the “petal_length”to see if there is a relationship.
<!--ID: 1617743193264-->




Multivariate Analysis #flashcard 
- Multivariate analysis is similar to Bivariate analysis but you are comparing more than two variables. For three variables, you can create a 3-D model to study the relationship (also known as Trivariate Analysis). However, since we cannot visualize anything above the third dimension, we often rely on other softwares and techniques for us to be able to grasp the relationship in the data.
- In terms of visualization, Seaborn library in Python allows for pairplots where it generates one large chart of selected variables against one another in a series of scatter plots and histograms depending on the type of variable, also known as scatter plot matrix. Again, in the series to come, I will provide the code and examples of this.
- Depending on the dataset and the depth of analysis required, there are other techniques that you could deploy, such as Principal Component Analysis or logistic regression, linear regression, cluster analysis, etc. Again, in the series to come, I will provide the code and examples of this and dive deeper into PCA and its importance in data.
<!--ID: 1617743200991-->




Secondary Vs primary #flashcard 
![[Pasted image 20210402171128.png]]
# primary you collect 
# secondary data - data that is collected by someone else 
<!--ID: 1617743209593-->


Data democratization #flashcard 
Data democratization is the ability for information in a digital format to be accessible to the average end user. The goal of data democratization is to allow non-specialists to be able to gather and analyze data without requiring outside help.
<!--ID: 1617743229691-->



Levels Of measurement #flashcard 
![[Pasted image 20210402172820.png]]
<!--ID: 1617743231066-->



What are some of the main reasons that projects fail? #flashcard 
Lack of Organization and Lack of Sponsor Support
<!--ID: 1617399331627-->

In House Data #flashcard 
Data that is already available for use
<!--ID: 1617743245564-->


Open Data #flashcard 
Data that is free and open to use
<!--ID: 1617743245586-->


API #flashcard 
Way of sharing data, routes data, translates data, gets it ready for use.
<!--ID: 1617743247188-->


Algebra VS linear algebra VS Calculus #flashcard 
Algebra - Math that allows you to scale up and generalize data
linear Algebra - Matrices and vectors
Calculus - Math used to determine Maximization and minimization 
<!--ID: 1617743260814-->





During Data Mining, why might an analyst resample a data set with replacement data? #flashcard 
Too little data for training and testing data sets
<!--ID: 1617743260834-->




Which concept should be considered when choosing variables for inclusion in a linear regression model? #flashcard 
Practical and Controllable
<!--ID: 1617743260848-->





Human in the Loop #flashcard 
Self Driving Cars, Medical Procedures, etc.
<!--ID: 1617743263688-->



Human Accessible #flashcard 
Home Loan Approval, Credit Card Approval, etc.
<!--ID: 1617743281584-->



Machine Centric  #flashcard 
Machines talking to other Machines, Smart Grid, etc.
<!--ID: 1617743281608-->


Data Scraping #flashcard 
Extracting data from formats that were not specifically designed for sharing?
<!--ID: 1617743296586-->



Open and Proprietary #flashcard 
What kind of data can be accessed by API's?
<!--ID: 1617743304312-->



Tidy Data #flashcard 
Columns are variables, rows are cases, and each file consists of one sheet at one level of observation.
![[Pasted image 20210403200157.png]]
<!--ID: 1617743304331-->


Active Listening #flashcard 
Cue into the verbal and nonverbal messages and the intent of what is being said
<!--ID: 1617743314440-->



Critical Listening #flashcard 
Evaluate and judge with the intent of looking at the logic of what is being heard
<!--ID: 1617743314457-->



Subject Matter Experts(SME) #flashcard 
people who know everything. They have been in a field for a long time and the "ins" and "outs"
<!--ID: 1617743319211-->




Outside people #flashcard 
Regulatory groups 
<!--ID: 1617743326139-->





What is Data Granularity? #flashcard 
- Data granularity is the level of detail considered in a model or decision making process or represented in an analysis report. The greater the granularity, the deeper the level of detail. Increased granularity can help you drill down on the details of each marketing channel and assess its efficacy, efficiency, and overall ROI.  
- For the pharma industry, knowing which marketing channels work for each brand segment or even HCP is far more informative than knowing what’s working for the company as a whole. Increased granularity can help you examine each brand’s performance and make specific, targeted adjustments to discrete variables to improve sales and profitability. Rather than using a shotgun approach, increasing data granularity allows you to focus your marketing with laser-scope precision.
<!--ID: 1617743333888-->




What is an example of an external stakeholder for a data analytics project? ---- #flashcard 
Regulatory body
<!--ID: 1617743336363-->





What elements make up "Big Data"? #flashcard 
==Volume, Velocity, Variety==
![[Pasted image 20210403184547.png]]
<!--ID: 1617743341779-->




Simple Linear regression #flashcard 
following models the ==relationship between a **dependent variable** and a single **independent variable**==
<!--ID: 1617743347609-->




Machine learning specialists #flashcard 
- People who use math and data science to advance artificial intelligence, such as Alexa.  
<!--ID: 1617743354139-->




Functional managers #flashcard 
– These are the bosses’ boss. They are the ones who oversee a couple data analyst teams or a section of the business, such as finance.
<!--ID: 1617743370808-->



Consultants- #flashcard 
Outside people who can help with specific ideas for a big picture in business.
<!--ID: 1617743372187-->





Bayes’ theorem - #flashcard 
Posterior probability as a function of the likelihood, the prior probability and the probability of getting the data you found. Used for medical diagnosis. If the person tests positive, on a a test that is 90% effective, what is the probability the person has the disease.
<!--ID: 1617743383862-->



Feature Selection - #flashcard 
A feature is a variable or dimension in the data. You can get data from the features of the data. You can combine these features to create a new feature.
<!--ID: 1617743383879-->




Dimensionality reduction (PCA & Factor Analysis) & Methods #flashcard 
The idea of dimension reduction is to actually reduce the number  of variables and the amount of data that you're dealing with. So instead of dealing with dozens or hundreds or maybe even thousands of variables, you're dealing with a single score like how likely a person is to behave in a particular way.
<!--ID: 1617743396010-->



Anomaly Detection  #flashcard 
the process of identifying rare or unexpected items or events in a data set that do not conform to other items in the data set. This can be serendipity - unexpected insights untapped potential/values. 
Finding anomalies: it can be fraud, process failure, potential value. All have in common: they are outliers. they don't follow expected patterns.
<!--ID: 1617743396028-->




Hierarchal Clustering  #flashcard 
Hierarchical clustering, also known as hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters.
<!--ID: 1617401799890-->



Neural networks #flashcard 
series of algorithms that mimic the operations of a human brain to recognize relationships between vast amounts of data.
<!--ID: 1617743410237-->




Decision trees #flashcard 
is a decision support tool that uses a tree-like model of 
decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.
<!--ID: 1617743410251-->




Optimization Analysis #flashcard 
Is a more complex extension of **goal-seeking analysis.**  Instead of setting a specific target value for a variable, the goal is to find the optimum value for one or more target variables, given certain constraints.
<!--ID: 1617743411636-->




Clustering   #flashcard  
Grouping data - can be geographical. 
K-Dimensional space: locate each data point, each observation, in a multidimensional space with K-dimensions for K variables. (KNN)



Conflict of interest:  #flashcard 
When the researching organization consciously ignores data that calls their results into question or only presents one side of the results that puts them in a positive light.
<!--ID: 1617743425183-->




Hard skills #flashcard 
1. Contract Management and
2.  Procurement '
3.  Risk Management
4. Budgeting and Scheduling 
5.  Planning 
<!--ID: 1617743426381-->




Data quality #flashcard 
![[Pasted image 20210403203646.png]]
<iframe src="https://giphy.com/embed/VhWVAa7rUtT3xKX6Cd" width="480" height="360" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/moodman-quality-nice-work-VhWVAa7rUtT3xKX6Cd">Good work</a></p>
<!--ID: 1617743435559-->

